{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXllGSV3yU/f3FrQDorHfV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmad162539/ML-class-excercise-codes/blob/main/MLclass%20horse%20and%20human.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3Ul_iVOqBXx",
        "outputId": "ffd3cc08-94de-4cca-d739-3dd85764928e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-23 03:30:34--  https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘horse-or-human.zip’\n",
            "\n",
            "horse-or-human.zip  100%[===================>] 142.65M   126MB/s    in 1.1s    \n",
            "\n",
            "2023-05-23 03:30:35 (126 MB/s) - ‘horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2023-05-23 03:30:35--  https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘validation-horse-or-human.zip’\n",
            "\n",
            "validation-horse-or 100%[===================>]  10.95M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-05-23 03:30:35 (123 MB/s) - ‘validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "https://storage.googleapis.com/download.tensorflow.org/data/horse-or-human.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "https://storage.googleapis.com/download.tensorflow.org/data/validation-horse-or-human.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -alf /home/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNLyVHbbrOy_",
        "outputId": "675daa03-4f54-49df-84b1-624dbfbd8435"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./  ../  horse_human/  validation_horse_human/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import zipfile"
      ],
      "metadata": {
        "id": "Sm48v-t-qD4v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_zip= \"horse-or-human.zip\"\n",
        "zip_ref= zipfile.ZipFile (local_zip, \"r\")\n",
        "zip_ref.extractall (\"/home/horse_human\")"
      ],
      "metadata": {
        "id": "pNbcWI1fqEZ2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_zip= \"validation-horse-or-human.zip\"\n",
        "zip_ref= zipfile.ZipFile (local_zip, \"r\")\n",
        "zip_ref.extractall (\"/home/validation_horse_human\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "ZOjG7qJ_q2wX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!Is -aIf /home/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpSpVKObrof3",
        "outputId": "6fcc0184-6ccb-4c70-cd24-2366773886a1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: Is: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen= ImageDataGenerator (rescale = 1/255)\n",
        "valid_datagen= ImageDataGenerator (rescale = 1/255)\n",
        "\n",
        "train_datagenerator = train_datagen.flow_from_directory (\"/home/horse_human\", target_size= (150,150), batch_size= 128, class_mode = \"binary\")\n",
        "valid_datagenerator = train_datagen.flow_from_directory (\"/home/validation_horse_human\", target_size= (150,150), batch_size= 128, class_mode = \"binary\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgE-92EdrFZX",
        "outputId": "51be3fae-bb5c-434d-c08e-ef1d63be01a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob \n",
        "from IPython.display import Image, display\n",
        "\n",
        "dir_image = \"/home/horse_human/horses/\"\n",
        "images = glob (dir_image + \"*,png\", recursive = False)\n",
        "\n",
        "print (len(images), \"images found in\", dir_image)\n",
        "\n",
        "for image in images [0:10]:\n",
        "  display (Image(image))\n",
        "  print (image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwf9IUNLsXJB",
        "outputId": "aa945b97-85e0-4977-f91b-a0dad910d9f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 images found in /home/horse_human/horses/\n"
          ]
        }
      ]
    }
  ]
}